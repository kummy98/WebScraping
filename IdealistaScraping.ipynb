{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7092bcd8",
   "metadata": {},
   "source": [
    "## scraping of Idealista.it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50a2f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca46d65",
   "metadata": {},
   "source": [
    "first of all we need some boring stuff like the headers\n",
    "\n",
    "\n",
    "headers are used to avoid being blocked when doing **data scrapring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06d0824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/100.0.4896.75 Safari/537.36',\n",
    "    'Accept-Language': 'it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,'\n",
    "              'application/signed-exchange;v=b3;q=0.9',\n",
    "    'sec-ch-ua': '\"Not A;Brand\";v=\"99\", \"Chromium\";v=\"100\", \"Google Chrome\";v=\"100\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'none',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4559ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here there is the url we are going to use \n",
    "\n",
    "URL = 'https://www.idealista.it/ajax/listingcontroller/livesearchmap.ajax?locationUri=&typology=1&o' \\\n",
    "      'peration=1&freeText=&liveSearch=true&zoom=16&northEast=45.45208275781088%2C+9.20756707023621' \\\n",
    "      '2&southWest=45.444857010779245%2C+9.1729129297638&uid=yk298widt7g0ropgx630dolk7vtndvt4l965nu' \\\n",
    "      'ebvl&adfilter_pricemin=default&adfilter_price=default&adfilter_area=default&adfilter_areamax=' \\\n",
    "      'default&adfilter_auctionability=default&adfilter_countryhouses=&adfilter_rooms_1=&adfilter_' \\\n",
    "      'rooms_2=&adfilter_rooms_3=&adfilter_rooms_4=&adfilter_rooms_5_more=&adfilter_baths_1=&adfilte' \\\n",
    "      'r_baths_2=&adfilter_baths_3=&adfilter_newconstruction=&adfilter_goodcondition=&adfilter_tobere' \\\n",
    "      'stored=&adfilter_hasairconditioning=&adfilter_wardrobes=&adfilter_lift=&adfilter_parkingspace=' \\\n",
    "      '&adfilter_garden=&adfilter_swimmingpool=&adfilter_hasterrace=&adfilter_boxroom=&adfilter_acces' \\\n",
    "      'sibleHousing=&adfilter_top_floor=&adfilter_intermediate_floor=&adfilter_ground_floor=&adfilter' \\\n",
    "      '_hasplan=&adfilter_digitalvisit=&adfilter_published=default&adfilter_onlyflats=&adfilter_penth' \\\n",
    "      'ouse=&adfilter_duplex=&adfilter_homes=&adfilter_independent=&adfilter_semidetached=&adfilter_t' \\\n",
    "      'erraced=&adfilter_villa=&adfilter_chalets='"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057f97b",
   "metadata": {},
   "source": [
    "here we need to use `json` to extract the link of our houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59d116e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# notice the headers = HEADERS, without it, print page would return an: Error 403\n",
    "\n",
    "page = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "print(page)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe0452",
   "metadata": {},
   "source": [
    "`<Response [200]>` is perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28d3daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we extract the json code\n",
    "\n",
    "parsedContent = json.loads(page.content)\n",
    "\n",
    "# print(parsedContent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe5719",
   "metadata": {},
   "source": [
    "and this is the same that you would see if you click on [URL](https://www.idealista.it/ajax/listingcontroller/livesearchmap.ajax?locationUri=&typology=1&operation=1&freeText=&liveSearch=true&zoom=16&northEast=45.45208275781088%2C+9.207567070236212&southWest=45.444857010779245%2C+9.1729129297638&uid=yk298widt7g0ropgx630dolk7vtndvt4l965nuebvl&adfilter_pricemin=default&adfilter_price=default&adfilter_area=default&adfilter_areamax=default&adfilter_auctionability=default&adfilter_countryhouses=&adfilter_rooms_1=&adfilter_rooms_2=&adfilter_rooms_3=&adfilter_rooms_4=&adfilter_rooms_5_more=&adfilter_baths_1=&adfilter_baths_2=&adfilter_baths_3=&adfilter_newconstruction=&adfilter_goodcondition=&adfilter_toberestored=&adfilter_hasairconditioning=&adfilter_wardrobes=&adfilter_lift=&adfilter_parkingspace=&adfilter_garden=&adfilter_swimmingpool=&adfilter_hasterrace=&adfilter_boxroom=&adfilter_accessibleHousing=&adfilter_top_floor=&adfilter_intermediate_floor=&adfilter_ground_floor=&adfilter_hasplan=&adfilter_digitalvisit=&adfilter_published=default&adfilter_onlyflats=&adfilter_penthouse=&adfilter_duplex=&adfilter_homes=&adfilter_independent=&adfilter_semidetached=&adfilter_terraced=&adfilter_villa=&adfilter_chalets=\n",
    ") link \n",
    "\n",
    "\n",
    "to better understand the `json` code you can use some sites that \"prettify\" the code like: [this](http://json.parser.online.fr/)\n",
    "\n",
    "\n",
    "here you can see that the `json` is like a gigantic dictionary where a lot of stuff are inside other stuff, so its important to understand what is inside what\n",
    "\n",
    "\n",
    "What we need is `adId`, all the link of the different houses are like https://www.idealista.it/immobile/24517268/, `adId` in this case is `24517268`, we need to extract all of them \n",
    "\n",
    "\n",
    "Trough the json viewer we see that `adId` its inside `items`, inside `map` and finally inside `jsonResponse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbe9fdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'adId': 24449334, 'adOperationId': 1, 'adTypologyId': 1, 'desc': '', 'detailURL': '', 'iconType': 0, 'latitude': 45.4465248, 'longitude': 9.1808377, 'numPics': 0, 'picturesURL': '', 'price': '', 'promocion': False, 'textInfo': '', 'thumbnail': ''}, {'adId': 23861265, 'adOperationId': 1, 'adTypologyId': 1, 'desc': '', 'detailURL': '', 'iconType': 0, 'latitude': 45.4493643, 'longitude': 9.1872556, 'numPics': 0, 'picturesURL': '', 'price': '', 'promocion': False, 'textInfo': '', 'thumbnail': ''}, {'adId': 24449862, 'adOperationId': 1, 'adTypologyId': 1, 'desc': '', 'detailURL': '', 'iconType': 0, 'latitude': 45.4488455, 'longitude': 9.1995805, 'numPics': 0, 'picturesURL': '', 'price': '', 'promocion': False, 'textInfo': '', 'thumbnail': ''}, {'adId': 23425985, 'adOperationId': 1, 'adTypologyId': 1, 'desc': '', 'detailURL': '', 'iconType': 0, 'latitude': 45.4485578, 'longitude': 9.1959022, 'numPics': 0, 'picturesURL': '', 'price': '', 'promocion': False, 'textInfo': '', 'thumbnail': ''}, {'adId': 24191930, 'adOperationId': 1, 'adTypologyId': 1, 'desc': '', 'detailURL': '', 'iconType': 1, 'latitude': 45.4516254, 'longitude': 9.19147, 'numPics': 0, 'picturesURL': '', 'price': '', 'promocion': False, 'textInfo': '', 'thumbnail': ''}]\n"
     ]
    }
   ],
   "source": [
    "print(parsedContent[\"jsonResponse\"][\"map\"][\"items\"][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34864f6",
   "metadata": {},
   "source": [
    "since its a list we can access the first element and extract the first `adId`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "482c5139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24449334\n"
     ]
    }
   ],
   "source": [
    "print(parsedContent[\"jsonResponse\"][\"map\"][\"items\"][0][\"adId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840a026",
   "metadata": {},
   "source": [
    "now we need to extract all of them, first we extract the total number of `adId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b905c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n"
     ]
    }
   ],
   "source": [
    "max_houses = parsedContent[\"jsonResponse\"][\"total\"]\n",
    "\n",
    "print(max_houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad27f0b",
   "metadata": {},
   "source": [
    "ok so we have a total of 346 houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "000219e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24449334, 23861265, 24449862, 23425985, 24191930, 23122812, 23560581, 23552800, 24455747, 23928278, 24167247, 24238132, 24251933, 23987790, 24064344, 24459888, 24458837, 24474070, 23956285, 24481891]\n"
     ]
    }
   ],
   "source": [
    "id_list = []\n",
    "\n",
    "for i in range(int(max_houses)):\n",
    "    id_list.append(parsedContent[\"jsonResponse\"][\"map\"][\"items\"][i][\"adId\"])\n",
    "\n",
    "print(id_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b393a13",
   "metadata": {},
   "source": [
    "top, now we need to create the links and we are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5641086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.idealista.it/immobile/24449334/', 'https://www.idealista.it/immobile/23861265/', 'https://www.idealista.it/immobile/24449862/', 'https://www.idealista.it/immobile/23425985/', 'https://www.idealista.it/immobile/24191930/', 'https://www.idealista.it/immobile/23122812/', 'https://www.idealista.it/immobile/23560581/', 'https://www.idealista.it/immobile/23552800/', 'https://www.idealista.it/immobile/24455747/', 'https://www.idealista.it/immobile/23928278/', 'https://www.idealista.it/immobile/24167247/', 'https://www.idealista.it/immobile/24238132/', 'https://www.idealista.it/immobile/24251933/', 'https://www.idealista.it/immobile/23987790/', 'https://www.idealista.it/immobile/24064344/', 'https://www.idealista.it/immobile/24459888/', 'https://www.idealista.it/immobile/24458837/', 'https://www.idealista.it/immobile/24474070/', 'https://www.idealista.it/immobile/23956285/', 'https://www.idealista.it/immobile/24481891/']\n"
     ]
    }
   ],
   "source": [
    "link_list = []\n",
    "url = 'https://www.idealista.it/immobile/'\n",
    "\n",
    "for id in id_list:\n",
    "    link_list.append(url + str(id) + '/')\n",
    "\n",
    "print(link_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74773944",
   "metadata": {},
   "source": [
    "lets try one link: https://www.idealista.it/immobile/23977397/\n",
    "\n",
    "ok perfect, now we have all of our link and for the moment we are done with `json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01273e2",
   "metadata": {},
   "source": [
    "## scraping of single house link info\n",
    "\n",
    "Now we need to extract the info from the link we have created: for this reason I have build the function `scrape_page` that receive as input the url of the house of interest and (for the moment) extract and only print the informations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f65da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    # input: url of the house\n",
    "    # output: row with all the desired info to insert in the df\n",
    "\n",
    "    page = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    print(url)\n",
    "    title = soup.find('span', class_='main-info__title-main')\n",
    "    title = title.get_text()\n",
    "    print(title)\n",
    "    place = soup.find('span', class_='main-info__title-minor')\n",
    "    place = place.get_text()\n",
    "    print(place)\n",
    "    price = soup.find('span', class_='txt-bold')\n",
    "    price = price.get_text()\n",
    "    print(price + ' €')\n",
    "    info = soup.find('div', class_='info-features')\n",
    "    size = info.find('span').find('span')\n",
    "    size = size.get_text()\n",
    "    print(size + ' m^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72994e",
   "metadata": {},
   "source": [
    "but before using `scrape_page` lets first understand a little bit how an `html` code is made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "375db263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.idealista.it/immobile/24449334/\n",
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "url = link_list[0]\n",
    "\n",
    "print(url)\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "print(page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe80bf1",
   "metadata": {},
   "source": [
    "and thats because we forgot to insert the `headers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2275313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.idealista.it/immobile/24449334/\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = link_list[0]\n",
    "\n",
    "print(url)\n",
    "\n",
    "page = requests.get(url, headers=HEADERS)\n",
    "\n",
    "print(page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705aaf7",
   "metadata": {},
   "source": [
    "and thats what we want!\n",
    "\n",
    "Now we need to extract the `html` code from `page`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1662a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbea01",
   "metadata": {},
   "source": [
    "and this is pretty much the same html code you see on the right on a web page when you press `inspect`.\n",
    "\n",
    "From here is difficult to understand whats is going on, but on the web page using inspect you can see which part of the code is responsible of which part of the web page:\n",
    "\n",
    "for example the title of the ad is under `<span class='main-info__title-main'>`, so we can extract it using `.find()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "173ce82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trilocale in vendita in via Antonio Tantardini, 11\n"
     ]
    }
   ],
   "source": [
    "title = soup.find('span', class_='main-info__title-main')\n",
    "title = title.get_text()\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60092c",
   "metadata": {},
   "source": [
    "and in this way we can extract everything: `title`, `place`, `size`, `price` and the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a4fbe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.idealista.it/immobile/24449334/\n",
      "Trilocale in vendita in via Antonio Tantardini, 11\n",
      "Bligny-Toscana, Milano\n",
      "770.000 €\n",
      "120 m^2\n"
     ]
    }
   ],
   "source": [
    "scrape_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c27222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
